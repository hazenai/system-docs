{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Hazen.ai System Documentation Image Cache sensor_type - 'rtsp' is used for rtsp stream, file is used for video file source, roseek for roseek camera cam_id - file path or stream addresss encoder - source reader encoder, supported values are \"gstreamer\", \"ffmpeg\" & \"v4l2\" DEFAULT is \"ffmpeg\" frame_source_timeout_sec - timeout value in seconds if the frame reading process from source is interrupted delay_for_file_ms - delay introduced in frames in case of video file, should be 0 for rtsp source_frame_rate - should only be set for ROSEEK, doesn't do anything in case of video file and rtsp stream jpeg_encoding - set to true if jpeg encoding is used in the pipeline size - capacity of image cache in frames debug_log - sets the debug log level to true or false, default log leve is INFO video_frame_rate - Image cache will automatically adjust the fps of video being written. This parameter can be used to slow down or speed up fps, e.g. 10 will speed up the fps by 10 and -10 will slow down. default should be 0, if no change is required color - color format of frames, can be true or false grpc_server_host - default 0.0.0.0 grpc_server_port - default 5000 threshold_ms - default 1000000 server_wait_sec - default 15 publish_on_redis - this parameter is true if a client requires a latest frame, should be false for ALPR cameras redis_server_host - default 0.0.0.0 redis_server_port - default 7000 redis_topic - default \"source_frames\" redis_timeout - default 2 Object Detector stream_type - 'gRPC' used to get images from image-cache and other options are rtsp, udp and file stream_address - file path or stream addresss sitename_camname - name of site timezone_of_video_file - in case of file, this is to specify the timezone of file. timeout_to_read_frame_sec - timeout value in seconds if the frame reading process from source is interrupted delay_to_getframe_ms - value in milliseconds to slow down frame reading process. jpeg_encoded - set to true if jpeg encoding is used in image-cache. pre_processor_type - specify the preprocessor you want to use depend upon the problem. possible values are traffic , seatbelt_mobilephone and trajectory . img_resize_width - set width to which you want to resize image in 'traffic' preprocessor. img_resize_height - set height to which you want to resize image in 'traffic' preprocessor. change_color_space_to_rgb - set true if want to change BGR image to RGB. increase_larger_side_by_factor - default 0.25, only for TLPD, to increase BBox of traffic light. increase_smaller_side_by_factor - default 0.25, only for TLPD, to increase BBox of traffic light. std_for_preprocess_img - default [0.229, 0.224, 0.225], set values to perform std of image. only for TLPD mean_for_preprocess_img - default [0.229, 0.224, 0.225], set values to perform mean of image. only for TLPD traffic_light_config - path to trafficlights.json file. do_resize_in_preprocessor - set true if you want to do resizing in preprocessor. infer_type - default 'tensorrt' for gpu based inference and openvino20 for cpu based infer. output_node_ids - only for openvino20 infer, depends upon engine. engine_file_path - path to engine file without extensions. batch_size - batch size passed to inference. trt_gpu_workspace_size - default '2.4' set trt gpu workspace size in Gibs enable_trt_preprocessor - set true if want to perform gpu based preprocessing. trt_preprocessor_input_dims - default [1080,1920,3] image dims, passed to gpu preprocessor in NHWC (Height, Width, channels) format. image_dims_infer_engine - default [3,1080,1980] image dims on which main infer engine will work in NCHW (channels, width, Height) format. post_processor_type - postprocessor you want. possible values are tlstatus , seatbelt_mobilephone and trajectory all_states - [\"red\", \"green\", \"yellow\", \"black\"], only for tlstatus to represent all states of trafficlight. class_map - \"0,1,2,3|black,green,red,yellow\" To represent infer result with respective classes. Before '|' is output of infer and after are the respective classes. state_machine_type - 'dynamic', only for tlstatus postprocessor. possible values dynamic and constant yellow_ticks_statemachine - default 18, only for tlstatus postprocessor yellow_tol_statemachine - default 5 green_th_state_statemachine - default 2 invalid_th_statemachine - default 10 yellow_floor_th_statemachine - default 2 yellow_ceil_th_statemachine - default 5 yellow_hist_buffer_statemachine - default 10 thres_hold_statemachine - default 1 group_count - default 2, total groups of trafficlight. lights_per_group - default [5, 0], total lights per group. classification_threshold - default 0.45, classification threshold for tlstatus postprocessor sensor_fusion_type - default 'majority', possible values are mean and majority debug_log - set true if want to see debug logs redis_host - redis host on which redis-server is running redis_port - port redis-server is running connection_timeout_secs - timeout value in seconds to connect to redis. topic - topic on which OD will publish packages. output_type - Specify type on which you want to get output of OD. Possible values are redis, mqtt and system_v_queue( only working for one specific case) group1_queue_id - queue id of system-v-queue on which want to get phase change status of group1(only for one specific case) group2_queue_id - queue id of system-v-queue on which want to get phase change status of group2(only for one specific case) config_trigger_queue - queue id on which OD will get notification about config change. (only for specific case) Object Tracker tracker_type - default 'hazenv2' use_objectness_score - For SBMP deployment use False , True otherwise tracked_classes - Tracker will track these classes for label smoothing. vehicle_type for trajectory and seatbelt|mobile_phone for SBMP log_level - default INFO, other value can be DEBUG redis_host - default 0.0.0.0, IP/domain of redis server redis_port - default 6379, port at which redis server is accessible listen_topic - tracker will subscribe to this topic for listening detections publish_topic - tracker will publish tracks to this topic sigma_l (float) - low score detection threshold sigma_iou (float) - default -0.05 sigma_len (int) - minimum track length in frames sigma_p (int) - maximum frames a track remains pending before termination sigma_h (float) - At least one detection in a track should have score greater than this output_pending_tracks - default False motion_model - default 'cppkalman' association_model - default 'hungarian' cost_model - default 'iou' Violation Service redis_host - IP/domain of redis server redis_port - Port at which redis server is accessible topic_for_od - Violation service will subscribe to this topic to listen for data sent directly by object detector e.g. TL Status topic_for_tracker - Violation service will subscribe to this topic to listen for track information sent by object tracker publish_topic - Violation Service will publish violations information on this topic log_level - Decides the log level of the service, can be DEBUG or INFO top_factor - Weight given to top of the bounding box while calculating the localization point of a detection. y-axis of point is top height + (1-top) height left_factor - Weight given to left side of the bounding box while calculating the localization point of a detection. x-axis of point is left width + (1-left) height image_height - Height of the annotated image image_width - Width of the annotated image alpr_video_duration_ms - Duration of the ALPR video request made by aggregator fps - Frame per second on which the system is running profiler_iterations - Iterations of the profiler, after which service will exit and profiler results will be dumped in a text file. This value should be -1 if profiler results are not required and if service is required to run for the lifecycle of other services Aggregator camera_cache_mapping - request_image_encoding - Get image of specific encoding. Typical values are jpg , png . request_image_offset_allowed_ms - queue_address - queue_port - queue_qos - queue_keep_alive - queue_event_topic - queue_violation_service_topic - queue_publisher_service_topic - event_storage_expiry - container_storage - log_level - generate_dummy_violation - map_to_wrongturn - map_to_wrongway - map_to_runningredlight - map_to_trespass_zebra - map_to_cellphone - map_to_seatbelt - publish_violations - redis_host - redis_port - Publisher package_receive_topic - edge_mqtt_address - edge_mqtt_port - package_receive_queue_qos - package_receive_queue_keep_alive - container_storage - cloud_mqtt_address - cloud_mqtt_port - cloud_publish_topic - cloud_queue_qos - cloud_queue_keep_alive - log_level - remote_publisher_enable_ssl - ca_certs - client_cert - client_key - redis_host - redis_port","title":"Config Documentation"},{"location":"#welcome-to-hazenai-system-documentation","text":"","title":"Welcome to Hazen.ai System Documentation"},{"location":"#image-cache","text":"sensor_type - 'rtsp' is used for rtsp stream, file is used for video file source, roseek for roseek camera cam_id - file path or stream addresss encoder - source reader encoder, supported values are \"gstreamer\", \"ffmpeg\" & \"v4l2\" DEFAULT is \"ffmpeg\" frame_source_timeout_sec - timeout value in seconds if the frame reading process from source is interrupted delay_for_file_ms - delay introduced in frames in case of video file, should be 0 for rtsp source_frame_rate - should only be set for ROSEEK, doesn't do anything in case of video file and rtsp stream jpeg_encoding - set to true if jpeg encoding is used in the pipeline size - capacity of image cache in frames debug_log - sets the debug log level to true or false, default log leve is INFO video_frame_rate - Image cache will automatically adjust the fps of video being written. This parameter can be used to slow down or speed up fps, e.g. 10 will speed up the fps by 10 and -10 will slow down. default should be 0, if no change is required color - color format of frames, can be true or false grpc_server_host - default 0.0.0.0 grpc_server_port - default 5000 threshold_ms - default 1000000 server_wait_sec - default 15 publish_on_redis - this parameter is true if a client requires a latest frame, should be false for ALPR cameras redis_server_host - default 0.0.0.0 redis_server_port - default 7000 redis_topic - default \"source_frames\" redis_timeout - default 2","title":"Image Cache"},{"location":"#object-detector","text":"stream_type - 'gRPC' used to get images from image-cache and other options are rtsp, udp and file stream_address - file path or stream addresss sitename_camname - name of site timezone_of_video_file - in case of file, this is to specify the timezone of file. timeout_to_read_frame_sec - timeout value in seconds if the frame reading process from source is interrupted delay_to_getframe_ms - value in milliseconds to slow down frame reading process. jpeg_encoded - set to true if jpeg encoding is used in image-cache. pre_processor_type - specify the preprocessor you want to use depend upon the problem. possible values are traffic , seatbelt_mobilephone and trajectory . img_resize_width - set width to which you want to resize image in 'traffic' preprocessor. img_resize_height - set height to which you want to resize image in 'traffic' preprocessor. change_color_space_to_rgb - set true if want to change BGR image to RGB. increase_larger_side_by_factor - default 0.25, only for TLPD, to increase BBox of traffic light. increase_smaller_side_by_factor - default 0.25, only for TLPD, to increase BBox of traffic light. std_for_preprocess_img - default [0.229, 0.224, 0.225], set values to perform std of image. only for TLPD mean_for_preprocess_img - default [0.229, 0.224, 0.225], set values to perform mean of image. only for TLPD traffic_light_config - path to trafficlights.json file. do_resize_in_preprocessor - set true if you want to do resizing in preprocessor. infer_type - default 'tensorrt' for gpu based inference and openvino20 for cpu based infer. output_node_ids - only for openvino20 infer, depends upon engine. engine_file_path - path to engine file without extensions. batch_size - batch size passed to inference. trt_gpu_workspace_size - default '2.4' set trt gpu workspace size in Gibs enable_trt_preprocessor - set true if want to perform gpu based preprocessing. trt_preprocessor_input_dims - default [1080,1920,3] image dims, passed to gpu preprocessor in NHWC (Height, Width, channels) format. image_dims_infer_engine - default [3,1080,1980] image dims on which main infer engine will work in NCHW (channels, width, Height) format. post_processor_type - postprocessor you want. possible values are tlstatus , seatbelt_mobilephone and trajectory all_states - [\"red\", \"green\", \"yellow\", \"black\"], only for tlstatus to represent all states of trafficlight. class_map - \"0,1,2,3|black,green,red,yellow\" To represent infer result with respective classes. Before '|' is output of infer and after are the respective classes. state_machine_type - 'dynamic', only for tlstatus postprocessor. possible values dynamic and constant yellow_ticks_statemachine - default 18, only for tlstatus postprocessor yellow_tol_statemachine - default 5 green_th_state_statemachine - default 2 invalid_th_statemachine - default 10 yellow_floor_th_statemachine - default 2 yellow_ceil_th_statemachine - default 5 yellow_hist_buffer_statemachine - default 10 thres_hold_statemachine - default 1 group_count - default 2, total groups of trafficlight. lights_per_group - default [5, 0], total lights per group. classification_threshold - default 0.45, classification threshold for tlstatus postprocessor sensor_fusion_type - default 'majority', possible values are mean and majority debug_log - set true if want to see debug logs redis_host - redis host on which redis-server is running redis_port - port redis-server is running connection_timeout_secs - timeout value in seconds to connect to redis. topic - topic on which OD will publish packages. output_type - Specify type on which you want to get output of OD. Possible values are redis, mqtt and system_v_queue( only working for one specific case) group1_queue_id - queue id of system-v-queue on which want to get phase change status of group1(only for one specific case) group2_queue_id - queue id of system-v-queue on which want to get phase change status of group2(only for one specific case) config_trigger_queue - queue id on which OD will get notification about config change. (only for specific case)","title":"Object Detector"},{"location":"#object-tracker","text":"tracker_type - default 'hazenv2' use_objectness_score - For SBMP deployment use False , True otherwise tracked_classes - Tracker will track these classes for label smoothing. vehicle_type for trajectory and seatbelt|mobile_phone for SBMP log_level - default INFO, other value can be DEBUG redis_host - default 0.0.0.0, IP/domain of redis server redis_port - default 6379, port at which redis server is accessible listen_topic - tracker will subscribe to this topic for listening detections publish_topic - tracker will publish tracks to this topic sigma_l (float) - low score detection threshold sigma_iou (float) - default -0.05 sigma_len (int) - minimum track length in frames sigma_p (int) - maximum frames a track remains pending before termination sigma_h (float) - At least one detection in a track should have score greater than this output_pending_tracks - default False motion_model - default 'cppkalman' association_model - default 'hungarian' cost_model - default 'iou'","title":"Object Tracker"},{"location":"#violation-service","text":"redis_host - IP/domain of redis server redis_port - Port at which redis server is accessible topic_for_od - Violation service will subscribe to this topic to listen for data sent directly by object detector e.g. TL Status topic_for_tracker - Violation service will subscribe to this topic to listen for track information sent by object tracker publish_topic - Violation Service will publish violations information on this topic log_level - Decides the log level of the service, can be DEBUG or INFO top_factor - Weight given to top of the bounding box while calculating the localization point of a detection. y-axis of point is top height + (1-top) height left_factor - Weight given to left side of the bounding box while calculating the localization point of a detection. x-axis of point is left width + (1-left) height image_height - Height of the annotated image image_width - Width of the annotated image alpr_video_duration_ms - Duration of the ALPR video request made by aggregator fps - Frame per second on which the system is running profiler_iterations - Iterations of the profiler, after which service will exit and profiler results will be dumped in a text file. This value should be -1 if profiler results are not required and if service is required to run for the lifecycle of other services","title":"Violation Service"},{"location":"#aggregator","text":"camera_cache_mapping - request_image_encoding - Get image of specific encoding. Typical values are jpg , png . request_image_offset_allowed_ms - queue_address - queue_port - queue_qos - queue_keep_alive - queue_event_topic - queue_violation_service_topic - queue_publisher_service_topic - event_storage_expiry - container_storage - log_level - generate_dummy_violation - map_to_wrongturn - map_to_wrongway - map_to_runningredlight - map_to_trespass_zebra - map_to_cellphone - map_to_seatbelt - publish_violations - redis_host - redis_port -","title":"Aggregator"},{"location":"#publisher","text":"package_receive_topic - edge_mqtt_address - edge_mqtt_port - package_receive_queue_qos - package_receive_queue_keep_alive - container_storage - cloud_mqtt_address - cloud_mqtt_port - cloud_publish_topic - cloud_queue_qos - cloud_queue_keep_alive - log_level - remote_publisher_enable_ssl - ca_certs - client_cert - client_key - redis_host - redis_port","title":"Publisher"},{"location":"flash/","text":"Guidlines to flash edge devices Axiomtek eBOX800-900-FL (Jetson TX2) Arrange a Host device (running ubuntu) Download Linux_for_Tegra_JP4.4_87900_T004.tar.gz from here on host device. Extract the downloaded file tar -xvzf Linux_for_Tegra_JP4.4_87900_T004.tar.gz . change directory cd Linux_for_Tegra_JP4.4_87900_T004/Linux_for_Tegra . Turn upside down the Axiomtek TX2 box and remove screws. Connect the micro usb cable from micro usb port on axiomtek TX2 (on CN7) to usb port on host device. Make the TX2 in recovery mode. See the process here On host device, run sudo ./flash.sh -r jetson-tx2 mmcblk0p1 . Wait till flashing is down. Remove tx2 from recovery mode and enable it to boot from internal eMMC by rebooting.","title":"Flashing Instructions"},{"location":"flash/#guidlines-to-flash-edge-devices","text":"","title":"Guidlines to flash edge devices"},{"location":"flash/#axiomtek-ebox800-900-fl-jetson-tx2","text":"Arrange a Host device (running ubuntu) Download Linux_for_Tegra_JP4.4_87900_T004.tar.gz from here on host device. Extract the downloaded file tar -xvzf Linux_for_Tegra_JP4.4_87900_T004.tar.gz . change directory cd Linux_for_Tegra_JP4.4_87900_T004/Linux_for_Tegra . Turn upside down the Axiomtek TX2 box and remove screws. Connect the micro usb cable from micro usb port on axiomtek TX2 (on CN7) to usb port on host device. Make the TX2 in recovery mode. See the process here On host device, run sudo ./flash.sh -r jetson-tx2 mmcblk0p1 . Wait till flashing is down. Remove tx2 from recovery mode and enable it to boot from internal eMMC by rebooting.","title":"Axiomtek eBOX800-900-FL (Jetson TX2)"},{"location":"installation/","text":"Basic Installation Guide for Seatbelt and Mobile phone System Deployment Prerequisites Edge device is flashed with Nvidia JetPack 4.4.0 (Make sure Jetson SDK Components are also installed) Internet Storage (at least 32GB) Edge Script Installtion Power Up your edge device and connect keyboard, mouse, monitor etc. Open terminal CTRL + ALT + T . Check if python3 is installed on device python3 --version . If not follow this link to install Check if nvidia-container-runtime is installed nvidia-container-runtime --version . If it's not installed, then install # Add the package repositories curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list # nvidia-container-runtime installation sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit nvidia-container-runtime sudo systemctl restart docker Download Edge Scripts wget GET_LINK_FROM_ABDULLAH Uncompress the downloaded file tar -xvzf AutoDeployment-1.2.0.tar.gz Change directory cd AutoDeployment-1.2.0/edge/ . Check if install.py and dependencies.yaml is present. Running the Edge Script RUN the install script sudo python3 install.py -d -p . -d flag will install system dependencies like docker, docker-compose and -p flag will set power mode on jetson devices. Now, answer the questions asked in command line. Select storage disk. Choose SD card NAME SIZE MOUNTPOINT UUID mmcblk0p1 14G / eda65433-df7c-4de9-8c4b-9ab2865b4f24 mmcblk1p1 234.7G /media/sdcard a10a85fe-a451-dd4c-b3b0-6862eb17eb56 Choose which disk to use for deployment[1-2]: 2 Select problem type Select the problem you want to deploy: 0: Video Light Phase Detection 1: SeatBelt/MobilePhone 2: Trajectory [0-2]: 1 Type your company name Please enter your company's name: hazenclient Select Power mode on Jetson devices. choose with id=2 ################ Collecting Hardware Info ####################### ## Power Model Selection on Jetson Devices ## ID=0 NAME=MODE_15W_2CORE ID=1 NAME=MODE_15W_4CORE ID=2 NAME=MODE_15W_6CORE ID=3 NAME=MODE_10W_2CORE ID=4 NAME=MODE_10W_4CORE Select Power Model. ID: 2 Now, script will start installing system dependencies. After system dependencies installation, script will install required services. This process may take 20-30 mins . Running the services Move to following directory cd $SD_CARD_MOUNTPOINT/hazen-test/imagetars/$COMPANY_NAME/ . For example, in this case, I will move to cd /media/sdcard/hazen-test/imagetars/hazenclient/ Run the following command sudo cp -r ./sbmp/* ./ Now, Run the services sudo ./run-services.sh","title":"Basic Installation"},{"location":"installation/#basic-installation-guide-for-seatbelt-and-mobile-phone-system-deployment","text":"","title":"Basic Installation Guide for Seatbelt and Mobile phone System Deployment"},{"location":"installation/#prerequisites","text":"Edge device is flashed with Nvidia JetPack 4.4.0 (Make sure Jetson SDK Components are also installed) Internet Storage (at least 32GB)","title":"Prerequisites"},{"location":"installation/#edge-script-installtion","text":"Power Up your edge device and connect keyboard, mouse, monitor etc. Open terminal CTRL + ALT + T . Check if python3 is installed on device python3 --version . If not follow this link to install Check if nvidia-container-runtime is installed nvidia-container-runtime --version . If it's not installed, then install # Add the package repositories curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list # nvidia-container-runtime installation sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit nvidia-container-runtime sudo systemctl restart docker Download Edge Scripts wget GET_LINK_FROM_ABDULLAH Uncompress the downloaded file tar -xvzf AutoDeployment-1.2.0.tar.gz Change directory cd AutoDeployment-1.2.0/edge/ . Check if install.py and dependencies.yaml is present.","title":"Edge Script Installtion"},{"location":"installation/#running-the-edge-script","text":"RUN the install script sudo python3 install.py -d -p . -d flag will install system dependencies like docker, docker-compose and -p flag will set power mode on jetson devices. Now, answer the questions asked in command line. Select storage disk. Choose SD card NAME SIZE MOUNTPOINT UUID mmcblk0p1 14G / eda65433-df7c-4de9-8c4b-9ab2865b4f24 mmcblk1p1 234.7G /media/sdcard a10a85fe-a451-dd4c-b3b0-6862eb17eb56 Choose which disk to use for deployment[1-2]: 2 Select problem type Select the problem you want to deploy: 0: Video Light Phase Detection 1: SeatBelt/MobilePhone 2: Trajectory [0-2]: 1 Type your company name Please enter your company's name: hazenclient Select Power mode on Jetson devices. choose with id=2 ################ Collecting Hardware Info ####################### ## Power Model Selection on Jetson Devices ## ID=0 NAME=MODE_15W_2CORE ID=1 NAME=MODE_15W_4CORE ID=2 NAME=MODE_15W_6CORE ID=3 NAME=MODE_10W_2CORE ID=4 NAME=MODE_10W_4CORE Select Power Model. ID: 2 Now, script will start installing system dependencies. After system dependencies installation, script will install required services. This process may take 20-30 mins .","title":"Running the Edge Script"},{"location":"installation/#running-the-services","text":"Move to following directory cd $SD_CARD_MOUNTPOINT/hazen-test/imagetars/$COMPANY_NAME/ . For example, in this case, I will move to cd /media/sdcard/hazen-test/imagetars/hazenclient/ Run the following command sudo cp -r ./sbmp/* ./ Now, Run the services sudo ./run-services.sh","title":"Running the services"},{"location":"site-rules-specs/","text":"Site Rules Specification A site configuration consists of 6 or 7 parameters depending on the requirements which are: Site Name Constants States Zones ALPR Zones Alias Rules Sample site configuration rules can be found here 1. Site Name Site name corresponds to the site where the service is deployed and is the first thing mentioned in the configuration. 2. Constants: Constants are the values which are required to be known by violation service beforehand and refer to values such as frame rate, image height, image width etc. etc. that remain almost the same in most of the sites. 3. States States are the factors whose values vary and depending on those values, it is determined whether an object has committed a violation or not. For example, for an object to commit a running red light violation, the value of the factor LIGHT has to be red. Different values of a same factor are written in a string, seperated by pipe characters: Light:\u200b \"red|yellow|green|black\" In the above example, Light is a factor and red , yellow , green , and black are the possible values. 4. Zones Zones are the annotated regions on an image which are used to determine the passage of an object on an intersection. The figure below shows an annotated frame with zones: Zones are defined as multipolygons and the corners of that polygon are mentioned in the configuration. Following operations can be performed on zones: + - corresponds to the union of two regions - - subtracts one zone from another zone * - gives the intersection of two zones 5. ALPR Zones: ALPR zones are defined if LPR is required in some scenarios. 6. Alias: Alias is a name given to a combination of zones. Enter:\u200b $Lane_1 + $Lane_2 + $Lane_3 Each zone involved in aliasing is preceded by a $ sign. 7. Rules: The first thing in a rule is its name followed by a sequence of rulelines. Rule name cannot have any spaces in it. Sample Rule with 4 rulelines: RunningRedLight: RL1: Zone: $Enter Shot: a_shot States: vehicle_category: '!person' Light: 'red' RL2: Zone: $ RL3: Zone: $Zebra_crossing Shot: b_shot States: Light: 'red' RL4: Zone: $Exit Here, \u2018RunningRedLight\u2019 is the name of the rule. Rulelines are defined later on as RL1 , RL2 , RL3 and RL4 . This rule defines a violation RunningRedLight in which an object commits a violation if it passes from Enter (defined as an alias) to Zebra_Crossing while the light is red and then passes through the Exit Zone. RL1 defines the zone as $Enter and Shot as a_shot and finally states are mentioned. Zones can either be given as an alias $Enter or they could be provided as an algebraic expression such as $Lane_1 + $Lane_2 + $Lane_3 . Both cases are acceptable. If a shot is required to be captured at the end of that zone, then Shot is defined in ruleline with its name which is a_shot in the above case. States in the ruleline provide the state of the environment at that instance which for Light is red and for vehicle category is !person . States in rulelines support following expressions: ! if a specific value of a factor has to be excluded. Like in the above example, the rule applies to every vehicle category except a person. | which performs the OR operation. For instance, if it was required that even crossing the region while the light is yellow is a violation, then State Light could be defined as Light: \u2018red|yellow\u2019. AND operator is not supported because the value of states are mutually exclusive, and there can\u2019t be two values of a single factor at a given time. Rest of the rulelines are defined in the same way as RL1 but RL2 is a unique ruleline, which is written when the regions between RL1 and RL3are disjoint. In that case a ruleline with Zone $ is defined, which corresponds to any region. So, if the Enter region and Zebra regions are disjoint, we don\u2019t care where the object goes in between them as long as it enters the Zebra region after entering the Enter region at some point. Another addition to the ruleline can be of the Duration parameter such as Duration: 1.5 where 1.5 is the duration in seconds. A rule employing the parameter Duration has been provided in the above sample configuration, named as EnteringRightRegion . Caveats ALPR zones are not used in rulelines. They are just defined in the beginning of the configuration and then violation service determines the LPR zone of the object committing the violation. Speaking of ALPR zones, LPR information would only be available if the ALPR zones are defined before the region used in the last ruleline of a rule. Composite zones are supported only as aliases or the zone subsection of rulelines. Sample Configurations Sample SeatBelt/MobilePhone site config with DEFAULT sitename. # site_config.yaml # I am a commented line DEFAULT: CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 8 STATES: seatbelt: \"violation|normal|cant_tell\" mobile_phone: \"normal|on_call|using_mobile|cant_tell\" ZONES: violation_region: [[0,0],[1920,0],[1920,1080],[0,1080]] RULES: Not_Wearing_Seatbelt: RL1: Zone: $violation_region Shot: c_shot States: seatbelt: 'violation' Using_Mobilephone: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'on_call|using_mobile' Sample Trajectory site config of a Site at Riyadh RIYADH: # Site Name CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 7 STATES: Light: \"red|yellow|green|black\" Time: \"Morning|Day|Evening|Night\" Day: \"Sunday|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday\" ZONES: Intersection: [[857, 458], [675, 368], [159, 404], [176, 510]] Left: [[4, 405], [159, 404], [176, 510], [4, 526]] Right: [[757, 407], [873, 466], [1071, 437], [971, 390]] Straight: [[263, 336], [516, 314], [582, 404], [244, 432]] RT_Lane: [[1328, 515], [1503, 498], [1901, 597], [1727, 658]] LT_Lane: [[216, 508], [393, 496], [1097, 1078], [464, 1078]] Lane_3: [[393, 496], [533, 484], [1860, 1078], [1097, 1078]] Lane_2: [[533, 484], [677, 473], [1917, 906], [1860, 1078]] Lane_1: [[677, 473], [820, 461], [1918, 755], [1917, 906]] Zebra: [[216, 508], [820, 461], [947, 507], [242, 568]] ALIAS: Enter: $Lane_1 + $Lane_2 + $Lane_3 + $LT_Lane + $RT_Lane Exit: $Left + $Right + $Straight RULES: # Event when an object runs a red light # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection while the light is red and then goes to # 2- Zebra region and then to # 3- Intersection and stays there for 1 second (with early capture) and then # Also, Since regions are disjoint empty ruleLines RL3 and RL6 are used Failure_to_Stop_at_RL: RL1: Zone: $Enter - $Zebra Shot: a_shot States: Light: 'red' RL2: Zone: $Zebra Shot: b_shot States: Light: 'red' RL3: Zone: $ RL4: Zone: $Intersection Duration: 1 Shot: c_shot States: Light: 'red' RL5: Zone: $Intersection RL6: Zone: $ RL7: Zone: $Exit # Event when an object takes a left turn from straight only lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with (Enter - Left) to # 3- Intersection to # 4- Left region Left_Turn_from_Wrong_Lane: RL1: Zone: ($Enter - $LT_Lane) - $Zebra Shot: a_shot RL2: Zone: ($Enter - $LT_Lane) * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection Shot: c_shot RL5: Zone: $Left # Event when an object goes straight from a turn only lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with Left Lane to # 3- Intersection to # 4- Straight region Straight_from_Turn_Only_Lane: RL1: Zone: $LT_Lane - ($LT_Lane * $Zebra) Shot: a_shot RL2: Zone: $LT_Lane * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection RL5: Zone: $Straight Shot: c_shot # Event when an object goes right from the wrong lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with intersection of Enter and Left Lane to # 3- Intersection to # 4- Right region Right_Turn_from_Wrong_Lane: RL1: Zone: ($Enter - $RT_Lane) - $Zebra Shot: a_shot RL2: Zone: ($Enter * $RT_Lane) * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection RL5: Zone: $Right Shot: c_shot # Event when an object blocks the pedestrain crossing # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- zebra and stays there for 3 seconds Block_Pedestrian_Crossing: RL1: Zone: $Enter - $RT_Lane - $Zebra Shot: a_shot RL2: Zone: $Zebra Duration: 3 Shot: c_shot States: Light: 'red' # Event when an object goes into a restricted lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is in a non-restricted zone # 2- Object goes to restricted zone and stays there for 1 second Driving_in_Restricted_Lane: RL1: Zone: $Enter - $LT_Lane Shot: a_shot RL2: Zone: $LT_Lane Duration: 1 Shot: b_shot Sample SB/MP site config for AI_ACTIVE AI_ACTIVE: CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 8 STATES: Seatbelt: \"violation|normal|cant_tell\" mobile_phone: \"normal|on_call|using_mobile|cant_tell\" ZONES: violation_region: [[1,161],[1530,92],[1917,374],[1916,804],[0,943], [1,161]] RULES: # Event when a driver is not wearing seatbelt # This event has just 1 shot. A violation region is defined and when an object # passes throught that region not wearing seatbelt, this event is triggered Not_Wearing_Seatbelt: RL1: Zone: $violation_region Shot: c_shot States: Seatbelt: 'violation' # Event when a driver is using mobile phone # This event has just 1 shot. A violation region is defined and when an object # passes throught that region using mobile phone, this event is triggered Using_Mobilephone: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'using_mobile' # Event when a driver is on call # This event has just 1 shot. A violation region is defined and when an object # passes throught that region using mobile phone, this event is triggered On_Call: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'on_call","title":"Site Rules Specification"},{"location":"site-rules-specs/#site-rules-specification","text":"A site configuration consists of 6 or 7 parameters depending on the requirements which are: Site Name Constants States Zones ALPR Zones Alias Rules Sample site configuration rules can be found here","title":"Site Rules Specification"},{"location":"site-rules-specs/#1-site-name","text":"Site name corresponds to the site where the service is deployed and is the first thing mentioned in the configuration.","title":"1. Site Name"},{"location":"site-rules-specs/#2-constants","text":"Constants are the values which are required to be known by violation service beforehand and refer to values such as frame rate, image height, image width etc. etc. that remain almost the same in most of the sites.","title":"2. Constants:"},{"location":"site-rules-specs/#3-states","text":"States are the factors whose values vary and depending on those values, it is determined whether an object has committed a violation or not. For example, for an object to commit a running red light violation, the value of the factor LIGHT has to be red. Different values of a same factor are written in a string, seperated by pipe characters: Light:\u200b \"red|yellow|green|black\" In the above example, Light is a factor and red , yellow , green , and black are the possible values.","title":"3. States"},{"location":"site-rules-specs/#4-zones","text":"Zones are the annotated regions on an image which are used to determine the passage of an object on an intersection. The figure below shows an annotated frame with zones: Zones are defined as multipolygons and the corners of that polygon are mentioned in the configuration. Following operations can be performed on zones: + - corresponds to the union of two regions - - subtracts one zone from another zone * - gives the intersection of two zones","title":"4. Zones"},{"location":"site-rules-specs/#5-alpr-zones","text":"ALPR zones are defined if LPR is required in some scenarios.","title":"5. ALPR Zones:"},{"location":"site-rules-specs/#6-alias","text":"Alias is a name given to a combination of zones. Enter:\u200b $Lane_1 + $Lane_2 + $Lane_3 Each zone involved in aliasing is preceded by a $ sign.","title":"6. Alias:"},{"location":"site-rules-specs/#7-rules","text":"The first thing in a rule is its name followed by a sequence of rulelines. Rule name cannot have any spaces in it. Sample Rule with 4 rulelines: RunningRedLight: RL1: Zone: $Enter Shot: a_shot States: vehicle_category: '!person' Light: 'red' RL2: Zone: $ RL3: Zone: $Zebra_crossing Shot: b_shot States: Light: 'red' RL4: Zone: $Exit Here, \u2018RunningRedLight\u2019 is the name of the rule. Rulelines are defined later on as RL1 , RL2 , RL3 and RL4 . This rule defines a violation RunningRedLight in which an object commits a violation if it passes from Enter (defined as an alias) to Zebra_Crossing while the light is red and then passes through the Exit Zone. RL1 defines the zone as $Enter and Shot as a_shot and finally states are mentioned. Zones can either be given as an alias $Enter or they could be provided as an algebraic expression such as $Lane_1 + $Lane_2 + $Lane_3 . Both cases are acceptable. If a shot is required to be captured at the end of that zone, then Shot is defined in ruleline with its name which is a_shot in the above case. States in the ruleline provide the state of the environment at that instance which for Light is red and for vehicle category is !person . States in rulelines support following expressions: ! if a specific value of a factor has to be excluded. Like in the above example, the rule applies to every vehicle category except a person. | which performs the OR operation. For instance, if it was required that even crossing the region while the light is yellow is a violation, then State Light could be defined as Light: \u2018red|yellow\u2019. AND operator is not supported because the value of states are mutually exclusive, and there can\u2019t be two values of a single factor at a given time. Rest of the rulelines are defined in the same way as RL1 but RL2 is a unique ruleline, which is written when the regions between RL1 and RL3are disjoint. In that case a ruleline with Zone $ is defined, which corresponds to any region. So, if the Enter region and Zebra regions are disjoint, we don\u2019t care where the object goes in between them as long as it enters the Zebra region after entering the Enter region at some point. Another addition to the ruleline can be of the Duration parameter such as Duration: 1.5 where 1.5 is the duration in seconds. A rule employing the parameter Duration has been provided in the above sample configuration, named as EnteringRightRegion .","title":"7. Rules:"},{"location":"site-rules-specs/#caveats","text":"ALPR zones are not used in rulelines. They are just defined in the beginning of the configuration and then violation service determines the LPR zone of the object committing the violation. Speaking of ALPR zones, LPR information would only be available if the ALPR zones are defined before the region used in the last ruleline of a rule. Composite zones are supported only as aliases or the zone subsection of rulelines.","title":"Caveats"},{"location":"site-rules-specs/#sample-configurations","text":"Sample SeatBelt/MobilePhone site config with DEFAULT sitename. # site_config.yaml # I am a commented line DEFAULT: CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 8 STATES: seatbelt: \"violation|normal|cant_tell\" mobile_phone: \"normal|on_call|using_mobile|cant_tell\" ZONES: violation_region: [[0,0],[1920,0],[1920,1080],[0,1080]] RULES: Not_Wearing_Seatbelt: RL1: Zone: $violation_region Shot: c_shot States: seatbelt: 'violation' Using_Mobilephone: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'on_call|using_mobile' Sample Trajectory site config of a Site at Riyadh RIYADH: # Site Name CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 7 STATES: Light: \"red|yellow|green|black\" Time: \"Morning|Day|Evening|Night\" Day: \"Sunday|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday\" ZONES: Intersection: [[857, 458], [675, 368], [159, 404], [176, 510]] Left: [[4, 405], [159, 404], [176, 510], [4, 526]] Right: [[757, 407], [873, 466], [1071, 437], [971, 390]] Straight: [[263, 336], [516, 314], [582, 404], [244, 432]] RT_Lane: [[1328, 515], [1503, 498], [1901, 597], [1727, 658]] LT_Lane: [[216, 508], [393, 496], [1097, 1078], [464, 1078]] Lane_3: [[393, 496], [533, 484], [1860, 1078], [1097, 1078]] Lane_2: [[533, 484], [677, 473], [1917, 906], [1860, 1078]] Lane_1: [[677, 473], [820, 461], [1918, 755], [1917, 906]] Zebra: [[216, 508], [820, 461], [947, 507], [242, 568]] ALIAS: Enter: $Lane_1 + $Lane_2 + $Lane_3 + $LT_Lane + $RT_Lane Exit: $Left + $Right + $Straight RULES: # Event when an object runs a red light # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection while the light is red and then goes to # 2- Zebra region and then to # 3- Intersection and stays there for 1 second (with early capture) and then # Also, Since regions are disjoint empty ruleLines RL3 and RL6 are used Failure_to_Stop_at_RL: RL1: Zone: $Enter - $Zebra Shot: a_shot States: Light: 'red' RL2: Zone: $Zebra Shot: b_shot States: Light: 'red' RL3: Zone: $ RL4: Zone: $Intersection Duration: 1 Shot: c_shot States: Light: 'red' RL5: Zone: $Intersection RL6: Zone: $ RL7: Zone: $Exit # Event when an object takes a left turn from straight only lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with (Enter - Left) to # 3- Intersection to # 4- Left region Left_Turn_from_Wrong_Lane: RL1: Zone: ($Enter - $LT_Lane) - $Zebra Shot: a_shot RL2: Zone: ($Enter - $LT_Lane) * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection Shot: c_shot RL5: Zone: $Left # Event when an object goes straight from a turn only lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with Left Lane to # 3- Intersection to # 4- Straight region Straight_from_Turn_Only_Lane: RL1: Zone: $LT_Lane - ($LT_Lane * $Zebra) Shot: a_shot RL2: Zone: $LT_Lane * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection RL5: Zone: $Straight Shot: c_shot # Event when an object goes right from the wrong lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- then to intersection of zebra with intersection of Enter and Left Lane to # 3- Intersection to # 4- Right region Right_Turn_from_Wrong_Lane: RL1: Zone: ($Enter - $RT_Lane) - $Zebra Shot: a_shot RL2: Zone: ($Enter * $RT_Lane) * $Zebra Shot: b_shot RL3: Zone: $ RL4: Zone: $Intersection RL5: Zone: $Right Shot: c_shot # Event when an object blocks the pedestrain crossing # This event has 3 shots. The object path follows the following pattern: # 1- Object is behind intersection then goes to # 2- zebra and stays there for 3 seconds Block_Pedestrian_Crossing: RL1: Zone: $Enter - $RT_Lane - $Zebra Shot: a_shot RL2: Zone: $Zebra Duration: 3 Shot: c_shot States: Light: 'red' # Event when an object goes into a restricted lane # This event has 3 shots. The object path follows the following pattern: # 1- Object is in a non-restricted zone # 2- Object goes to restricted zone and stays there for 1 second Driving_in_Restricted_Lane: RL1: Zone: $Enter - $LT_Lane Shot: a_shot RL2: Zone: $LT_Lane Duration: 1 Shot: b_shot Sample SB/MP site config for AI_ACTIVE AI_ACTIVE: CONSTANTS: IMAGE_WIDTH: 1920 IMAGE_HEIGHT: 1080 FPS: 8 STATES: Seatbelt: \"violation|normal|cant_tell\" mobile_phone: \"normal|on_call|using_mobile|cant_tell\" ZONES: violation_region: [[1,161],[1530,92],[1917,374],[1916,804],[0,943], [1,161]] RULES: # Event when a driver is not wearing seatbelt # This event has just 1 shot. A violation region is defined and when an object # passes throught that region not wearing seatbelt, this event is triggered Not_Wearing_Seatbelt: RL1: Zone: $violation_region Shot: c_shot States: Seatbelt: 'violation' # Event when a driver is using mobile phone # This event has just 1 shot. A violation region is defined and when an object # passes throught that region using mobile phone, this event is triggered Using_Mobilephone: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'using_mobile' # Event when a driver is on call # This event has just 1 shot. A violation region is defined and when an object # passes throught that region using mobile phone, this event is triggered On_Call: RL1: Zone: $violation_region Shot: c_shot States: mobile_phone: 'on_call","title":"Sample Configurations"}]}